@article{Haug2015,
abstract = {In this paper we propose a benchmark dataset for crop/weed discrimination, single plant phenotyping and other open computer vision tasks in precision agriculture. The dataset comprises 60 images with annotations and is available online (http://​github.​com/​cwfid). All images were acquired with the autonomous field robot Bonirob in an organic carrot farm while the carrot plants were in early true leaf growth stage. Intra- and inter-row weeds were present, weed and crop were approximately of the same size and grew close together. For every dataset image we supply a ground truth vegetation segmentation mask and manual annotation of the plant type (crop vs. weed). We provide initial results for the phenotyping problem of crop/weed classification and propose evaluation methods to allow comparison of different approaches. By opening this dataset to the community we want to stimulate research in this area where the current lack of public datasets is one of the barriers for progress.},
author = {Haug, Sebastian and Ostermann, J{\"{o}}rn},
doi = {10.1007/978-3-319-16220-1_8},
file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/JupyterNotebook/dataset-1.0/paper.pdf:pdf},
isbn = {9783319162195},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Bonirob field robot,Classification,Computer vision,Dataset,Phenotyping,Precision agriculture},
mendeley-groups = {ML},
pages = {105--116},
title = {{A crop/weed field image dataset for the evaluation of computer vision based precision agriculture tasks}},
volume = {8928},
year = {2015}
}


@ARTICLE{5392560, 
	author={A. L. Samuel}, 
	journal={IBM Journal of Research and Development}, 
	title={Some Studies in Machine Learning Using the Game of Checkers}, 
	year={1959}, 
	volume={3}, 
	number={3}, 
	pages={210-229}, 
	keywords={}, 
	doi={10.1147/rd.33.0210}, 
	ISSN={0018-8646}, 
	month={July}}

@article{Domingos2012,
	abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
	archivePrefix = {arXiv},
	arxivId = {cs/9605103},
	author = {Domingos, Pedro},
	doi = {10.1145/2347736.2347755},
	eprint = {9605103},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/cacm12.pdf:pdf},
	isbn = {0001-0782},
	issn = {00010782},
	journal = {Communications of the ACM},
	mendeley-groups = {ML},
	number = {10},
	pages = {78},
	pmid = {1000183096},
	primaryClass = {cs},
	title = {{A few useful things to know about machine learning}},
	url = {http://dl.acm.org/citation.cfm?doid=2347736.2347755},
	volume = {55},
	year = {2012}
}


@article{Ratsch2004,
	abstract = {The Machine Learning field evolved from the broad field of Artificial Intelligence, which aims to mimic intelligent abilities of humans by machines. In the field of Ma- chine Learning one considers the important question of how to make machines able to “learn”. Learning in this context is understood as inductive inference, where one observes examples that represent incomplete information about some “statistical phe- nomenon”. In unsupervised learning one typically tries to uncover hidden regularities (e.g. clusters) or to detect anomalies in the data (for instance some unusual machine function or a network intrusion). In supervised learning, there is a label associated with each example. It is supposed to be the answer to a question about the example. If the label is discrete, then the task is called classification problem – otherwise, for real- valued labels we speak of a regression problem. Based on these examples (including the labels), one is particularly interested to predict the answer for other cases before they are explicitly observed. Hence, learning is not only a question of remembering but also of generalization to unseen cases.},
	author = {R{\"{a}}tsch, G},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/105-machine-learning-paper.pdf:pdf},
	journal = {21st Chaos Communication Congress},
	mendeley-groups = {ML},
	pages = {1--6},
	title = {{A brief introduction into machine learning}},
	url = {http://www.mva.me/educational/hci/read/ML{\_}reading.pdf},
	year = {2004}
}


 @misc{BOSH,
	title  = "Autonomous field robot Bonirob",
	author = "BOSH",
	url    = "https://www.deepfield-robotics.com/",
	note   = "\url{https://www.deepfield-robotics.com/}",
	year   = "2017 (accessed December 10, 2017)"
}


 @misc{sift,
	title  = "SIFT Descriptor",
	author = "VLFeat.org",
	url    = "http://www.vlfeat.org/api/sift.html",
	note   = "\url{http://www.vlfeat.org/api/sift.html}",
	year   = "2017 (accessed December 10, 2017)"
}


 @misc{mathw,
	title  = "Image Classification with Bag of Visual Wordsr",
	author = "The MathWorks, Inc.",
	url    = "https://www.mathworks.com/help/vision/ug/image-classification-with-bag-of-visual-words.html",
	note   = "\url{https://www.mathworks.com/help/vision/ug/image-classification-with-bag-of-visual-words.htmll}",
	year   = "2017 (accessed December 22, 2017)"
}





@article{Arandjelovic2013,
	abstract = {The objective of this paper is large scale object instance retrieval, given a query image. A starting point of such systems is feature detection and description, for example using SIFT. The focus of this paper, however, is towards very large scale retrieval where, due to storage requirements, very compact image descriptors are required and no information about the original SIFT descriptors can be accessed directly at run time. We start from VLAD, the state-of-the art compact descriptor introduced by Jegou et al. for this purpose, and make three novel contributions: first, we show that a simple change to the normalization method significantly improves retrieval performance, second, we show that vocabulary adaptation can substantially alleviate problems caused when images are added to the dataset after initial vocabulary learning. These two methods set a new state-of-the-art over all benchmarks investigated here for both mid-dimensional (20k-D to 30k-D) and small (128-D) descriptors. Our third contribution is a multiple spatial VLAD representation, MultiVLAD, that allows the retrieval and localization of objects that only extend over a small part of an image (again without requiring use of the original image SIFT descriptors). View full abstract},
	author = {Arandjelovic, Relja and Zisserman, Andrew},
	doi = {10.1109/CVPR.2013.207},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/arandjelovic13.pdf:pdf},
	isbn = {978-0-7695-4989-7},
	issn = {10636919},
	journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},
	mendeley-groups = {ML},
	pages = {1578--1585},
	title = {{All About VLAD}},
	url = {http://ieeexplore.ieee.org/document/6619051/},
	year = {2013}
}


@article{Delhumeau2013,
	abstract = {Recent works on image retrieval have proposed to index images by compact representations encoding powerful local descriptors, such as the closely related VLAD and Fisher vector. By combining such a representation with a suitable coding technique, it is possible to encode an image in a few dozen bytes while achieving excellent retrieval results. This paper revisits some assumptions proposed in this context regarding the handling of "visual burstiness", and shows that ad-hoc choices are implicitly done which are not desirable. Focusing on VLAD without loss of generality, we propose to modify several steps of the original design. Albeit simple, these modifications significantly improve VLAD and make it compare favorably against the state of the art.},
	author = {Delhumeau, Jonathan and Gosselin, Philippe-Henri and J{\'{e}}gou, Herv{\'{e}} and P{\'{e}}rez, Patrick},
	doi = {10.1145/2502081.2502171},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/delhumeau13acmm.pdf:pdf},
	isbn = {9781450324045},
	journal = {Proceedings of the 21st ACM international conference on Multimedia - MM '13},
	keywords = {image search,multimedia retrieval,vlad},
	mendeley-groups = {ML},
	pages = {653--656},
	title = {{Revisiting the VLAD image representation}},
	url = {http://dl.acm.org/citation.cfm?doid=2502081.2502171},
	year = {2013}
}




@article{Sanchez2013,
	author = {Sanchez, Jorge and Perronnin, Florent and Mensink, Thomas and Verbeek, Jakob and Classification, Image and Jorge, S and Thomas, Perronnin and Jakob, Mensink},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/RR-8209.pdf:pdf},
	mendeley-groups = {ML},
	title = {{Image Classification with the Fisher Vector : Theory and Practice To cite this version : Image Classification with the Fisher Vector : Theory and Practice}},
	year = {2013}
}


@article{Horning2010,
	abstract = {9-11 December 2010},
	archivePrefix = {arXiv},
	arxivId = {1609-3631},
	author = {Horning, N.},
	doi = {10.5244/C.22.54},
	eprint = {1609-3631},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/04aa1f4a8beb619e7fe711c29b7b.pdf:pdf},
	isbn = {3021077226},
	issn = {1550-5499},
	journal = {International Conference on Geoinformatics for Spatial Infrastructure Development in Earth and Allied Sciences 2010},
	mendeley-groups = {ML},
	pages = {1--6},
	pmid = {21196786},
	title = {{Random Forests: An algorithm for image classification and generation of continuous fields data sets}},
	year = {2010}
}


@article{Bosch2007,
	abstract = {We explore the problem of classifying images by the object categories they contain in the case of a large number of object categories. To this end we combine three ingredients: (i) shape and appearance representations that support spatial pyramid matching over a region of interest. This generalizes the representation of Lazebnik et al [16] from an image to a region of interest (ROI), and from appearance (visual words) alone to appearance and local shape (edge distributions). (ii) automatic selection of the regions of interest in training. This provides a method of inhibiting background clutter and adding invariance to the object instance's position, and (iii) the use of random forests (and random ferns) as a multi-way classifier. The advantage of such classifiers (over multi-way SVM for example) is the ease of training and testing. Results are reported for classification of the Caltech-101 and Caltech-256 data sets. We compare the performance of the random forest/ferns classifier with a benchmark multi-way SVM classifier. It is shown that selecting the ROI adds about 5{\%} to the performance and, together with the other improvements, the result is about a 10{\%} improvement over the state of the art for Caltech-256.},
	author = {Bosch, Anna and Zisserman, Andrew and Mu, Xavier and Munoz, Xavier},
	doi = {10.1109/ICCV.2007.4409066},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/bosch07a.pdf:pdf},
	isbn = {1550-5499 VO -},
	issn = {1550-5499},
	journal = {Computer Vision (ICCV), IEEE 11th International Conference on},
	mendeley-groups = {ML},
	pages = {1--8},
	title = {{Image Classification Using Random Forests and Ferns}},
	url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4409066},
	year = {2007}
}

@article{Singh2012,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1412.7062v1},
	author = {Singh, Nishant and Dubey, Shiv Ram and Dixit, Pushkar and Gupta, Jay Prakash},
	doi = {10.5121/csit.2012.2327},
	eprint = {arXiv:1412.7062v1},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/csit53203 (1).pdf:pdf},
	mendeley-groups = {ML},
	number = {2},
	pages = {277--284},
	title = {{Semantic Image Retrieval Using Multiple Features}},
	volume = {5},
	year = {2012}
}


@article{Ke2003,
	author = {Ke, Yan and Sukthankar, Rahul},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/cvpr2004-keypoint-rahuls.pdf:pdf},
	mendeley-groups = {ML},
	pages = {2--9},
	title = {{A More Distinctive Representation for Local Image Descriptors}},
	year = {2003}
}



@article{Jegou2010,
	abstract = {We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms.},
	author = {J{\'{e}}gou, Herv{\'{e}} and Douze, Matthijs and Schmid, Cordelia and P{\'{e}}rez, Patrick},
	doi = {10.1109/CVPR.2010.5540039},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/jegou{\_}compactimagerepresentation.pdf:pdf},
	isbn = {9781424469840},
	issn = {10636919},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	mendeley-groups = {ML},
	pages = {3304--3311},
	pmid = {22156101},
	title = {{Aggregating local descriptors into a compact image representation}},
	year = {2010}
}

@article{Diba,
	author = {Diba, Ali},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/MVA17{\_}0121{\_}FI.pdf:pdf},
	mendeley-groups = {ML},
	title = {{Deep Visual Words : Improved Fisher Vector for Image Classification}}
}



@article{Liu2016,
	abstract = {Deriving from the gradient vector of a generative model of local features, Fisher vector coding (FVC) has been identified as an effective coding method for image classification. Most, if not all, FVC implementations employ the Gaussian mixture model (GMM) to depict the generation process of local features. However, the representative power of the GMM could be limited because it essentially assumes that local features can be characterized by a fixed number of feature prototypes and the number of prototypes is usually small in FVC. To handle this limitation, in this paper we break the convention which assumes that a local feature is drawn from one of few Gaussian distributions. Instead, we adopt a compositional mechanism which assumes that a local feature is drawn from a Gaussian distribution whose mean vector is composed as the linear combination of multiple key components and the combination weight is a latent random variable. In this way, we can greatly enhance the representative power of the generative model of FVC. To implement our idea, we designed two particular generative models with such a compositional mechanism.},
	archivePrefix = {arXiv},
	arxivId = {1601.04143},
	author = {Liu, Lingqiao and Wang, Peng and Shen, Chunhua and Wang, Lei and van den Hengel, Anton and Wang, Chao and Shen, Heng Tao},
	doi = {10.1109/TPAMI.2017.2651061},
	eprint = {1601.04143},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/1601.04143.pdf:pdf},
	issn = {0162-8828},
	mendeley-groups = {ML},
	pages = {1--16},
	title = {{Compositional Model based Fisher Vector Coding for Image Classification}},
	url = {http://arxiv.org/abs/1601.04143},
	year = {2016}
}


@article{Uchida2013,
	abstract = {Recently, the Fisher vector representation of local features has attracted much attention because of its effectiveness in both image classification and image retrieval. Another trend in the area of image retrieval is the use of binary features such as ORB, FREAK, and BRISK. Considering the significant performance improvement for accuracy in both image classification and retrieval by the Fisher vector of continuous feature descriptors, if the Fisher vector were also to be applied to binary features, we would receive similar benefits in binary feature based image retrieval and classification. In this paper, we derive the closed-form approximation of the Fisher vector of binary features modeled by the Bernoulli mixture model. We also propose accelerating the Fisher vector by using the approximate value of posterior probability. Experiments show that the Fisher vector representation significantly improves the accuracy of image retrieval compared with a bag of binary words approach.},
	archivePrefix = {arXiv},
	arxivId = {1609.08291},
	author = {Uchida, Yusuke and Sakazawa, Shigeyuki},
	doi = {10.1109/ACPR.2013.6},
	eprint = {1609.08291},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/1609.08291.pdf:pdf},
	isbn = {978-1-4799-2190-4},
	issn = {21867364},
	journal = {Proceedings - 2nd IAPR Asian Conference on Pattern Recognition, ACPR 2013},
	keywords = {Bernoulli mixture model,Binary feature,Fisher vector,Image retrieval},
	mendeley-groups = {ML},
	pages = {23--28},
	title = {{Image retrieval with fisher vectors of binary features}},
	year = {2013}
}

@article{Sun2013,
	abstract = {Event recognition has been an important topic in computer vision research due to its many applications. However, most of the work has focused on videos taken from a fixed camera, known environments and basic events. Here, we focus on classification of unconstrained, web videos into much higher level activities. We follow the approach of constructing fixed length feature vectors from local feature descriptors for classification using an SVM. Our key contribution is the study of the utility of Fisher Vector representation in improving results compared to the conventional Bag-of-Words (BoW) approach. Such coding has shown to be useful for static image classification in the past but not applied to video categorization. We perform tests on the challenging NIST TRECVID Multimedia Event Detection (MED) dataset, which has thousand hours of unconstrained user generated videos; our approach achieves as much as 35{\%} improvement over the BoW baseline. We also offer an analysis of possible causes of such improvements.},
	author = {Sun, Chen and Nevatia, Ram},
	doi = {10.1109/WACV.2013.6474994},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/9e7783a225db266475160dcbcf29ff5b47df.pdf:pdf},
	isbn = {9781467350532},
	issn = {21583978},
	journal = {Proceedings of IEEE Workshop on Applications of Computer Vision},
	mendeley-groups = {ML},
	pages = {15--22},
	title = {{Large-scale web video event classification by use of Fisher Vectors}},
	year = {2013}
}

@article{Triola,
	author = {Triola, Mario F},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/BayesTheorem.pdf:pdf},
	mendeley-groups = {ML},
	pages = {1--9},
	year = {2000},
	title = {{Bayes ' Theorem}}
}



@Inbook{Jiang2007,
	author="Jiang, Liangxiao
	and Wang, Dianhong
	and Cai, Zhihua
	and Yan, Xuesong",
	editor="Alhajj, Reda
	and Gao, Hong
	and Li, Jianzhong
	and Li, Xue
	and Za{\"i}ane, Osmar R.",
	title="Survey of Improving Naive Bayes for Classification",
	bookTitle="Advanced Data Mining and Applications: Third International Conference, ADMA 2007 Harbin, China, August 6-8, 2007. Proceedings",
	year="2007",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="134--145",
	abstract="The attribute conditional independence assumption of naive Bayes essentially ignores attribute dependencies and is often violated. On the other hand, although a Bayesian network can represent arbitrary attribute dependencies, learning an optimal Bayesian network classifier from data is intractable. Thus, learning improved naive Bayes has attracted much attention from researchers and presented many effective and efficient improved algorithms. In this paper, we review some of these improved algorithms and single out four main improved approaches: 1) Feature selection; 2) Structure extension; 3) Local learning; 4) Data expansion. We experimentally tested these approaches using the whole 36 UCI data sets selected by Weka, and compared them to naive Bayes. The experimental results show that all these approaches are effective. In the end, we discuss some main directions for future research on Bayesian network classifiers.",
	isbn="978-3-540-73871-8",
	doi="10.1007/978-3-540-73871-8_14",
	url="https://doi.org/10.1007/978-3-540-73871-8_14"
}

@inproceedings{haug15,
	author={Haug, Sebastian and Ostermann, J{\"o}rn},
	title={A Crop/Weed Field Image Dataset for the Evaluation of Computer Vision Based Precision Agriculture Tasks},
	year={2015},
	booktitle={Computer Vision - ECCV 2014 Workshops},
	doi={10.1007/978-3-319-16220-1_8},
	url={http://dx.doi.org/10.1007/978-3-319-16220-1_8},
	pages={105--116},
}
