@article{Haug2015,
abstract = {In this paper we propose a benchmark dataset for crop/weed discrimination, single plant phenotyping and other open computer vision tasks in precision agriculture. The dataset comprises 60 images with annotations and is available online (http://​github.​com/​cwfid). All images were acquired with the autonomous field robot Bonirob in an organic carrot farm while the carrot plants were in early true leaf growth stage. Intra- and inter-row weeds were present, weed and crop were approximately of the same size and grew close together. For every dataset image we supply a ground truth vegetation segmentation mask and manual annotation of the plant type (crop vs. weed). We provide initial results for the phenotyping problem of crop/weed classification and propose evaluation methods to allow comparison of different approaches. By opening this dataset to the community we want to stimulate research in this area where the current lack of public datasets is one of the barriers for progress.},
author = {Haug, Sebastian and Ostermann, J{\"{o}}rn},
doi = {10.1007/978-3-319-16220-1_8},
file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/JupyterNotebook/dataset-1.0/paper.pdf:pdf},
isbn = {9783319162195},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Bonirob field robot,Classification,Computer vision,Dataset,Phenotyping,Precision agriculture},
mendeley-groups = {ML},
pages = {105--116},
title = {{A crop/weed field image dataset for the evaluation of computer vision based precision agriculture tasks}},
volume = {8928},
year = {2015}
}


@ARTICLE{5392560, 
	author={A. L. Samuel}, 
	journal={IBM Journal of Research and Development}, 
	title={Some Studies in Machine Learning Using the Game of Checkers}, 
	year={1959}, 
	volume={3}, 
	number={3}, 
	pages={210-229}, 
	keywords={}, 
	doi={10.1147/rd.33.0210}, 
	ISSN={0018-8646}, 
	month={July}}

@article{Domingos2012,
	abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
	archivePrefix = {arXiv},
	arxivId = {cs/9605103},
	author = {Domingos, Pedro},
	doi = {10.1145/2347736.2347755},
	eprint = {9605103},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/cacm12.pdf:pdf},
	isbn = {0001-0782},
	issn = {00010782},
	journal = {Communications of the ACM},
	mendeley-groups = {ML},
	number = {10},
	pages = {78},
	pmid = {1000183096},
	primaryClass = {cs},
	title = {{A few useful things to know about machine learning}},
	url = {http://dl.acm.org/citation.cfm?doid=2347736.2347755},
	volume = {55},
	year = {2012}
}


@article{Ratsch2004,
	abstract = {The Machine Learning field evolved from the broad field of Artificial Intelligence, which aims to mimic intelligent abilities of humans by machines. In the field of Ma- chine Learning one considers the important question of how to make machines able to “learn”. Learning in this context is understood as inductive inference, where one observes examples that represent incomplete information about some “statistical phe- nomenon”. In unsupervised learning one typically tries to uncover hidden regularities (e.g. clusters) or to detect anomalies in the data (for instance some unusual machine function or a network intrusion). In supervised learning, there is a label associated with each example. It is supposed to be the answer to a question about the example. If the label is discrete, then the task is called classification problem – otherwise, for real- valued labels we speak of a regression problem. Based on these examples (including the labels), one is particularly interested to predict the answer for other cases before they are explicitly observed. Hence, learning is not only a question of remembering but also of generalization to unseen cases.},
	author = {R{\"{a}}tsch, G},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/105-machine-learning-paper.pdf:pdf},
	journal = {21st Chaos Communication Congress},
	mendeley-groups = {ML},
	pages = {1--6},
	title = {{A brief introduction into machine learning}},
	url = {http://www.mva.me/educational/hci/read/ML{\_}reading.pdf},
	year = {2004}
}


 @misc{BOSH,
	title  = "Autonomous field robot Bonirob",
	author = "BOSH",
	url    = "https://www.deepfield-robotics.com/",
	note   = "\url{https://www.deepfield-robotics.com/}",
	year   = "2017 (accessed December 10, 2017)"
}


 @misc{sift,
	title  = "SIFT Descriptor",
	author = "VLFeat.org",
	url    = "http://www.vlfeat.org/api/sift.html",
	note   = "\url{http://www.vlfeat.org/api/sift.html}",
	year   = "2017 (accessed December 10, 2017)"
}

@article{Arandjelovic2013,
	abstract = {The objective of this paper is large scale object instance retrieval, given a query image. A starting point of such systems is feature detection and description, for example using SIFT. The focus of this paper, however, is towards very large scale retrieval where, due to storage requirements, very compact image descriptors are required and no information about the original SIFT descriptors can be accessed directly at run time. We start from VLAD, the state-of-the art compact descriptor introduced by Jegou et al. for this purpose, and make three novel contributions: first, we show that a simple change to the normalization method significantly improves retrieval performance, second, we show that vocabulary adaptation can substantially alleviate problems caused when images are added to the dataset after initial vocabulary learning. These two methods set a new state-of-the-art over all benchmarks investigated here for both mid-dimensional (20k-D to 30k-D) and small (128-D) descriptors. Our third contribution is a multiple spatial VLAD representation, MultiVLAD, that allows the retrieval and localization of objects that only extend over a small part of an image (again without requiring use of the original image SIFT descriptors). View full abstract},
	author = {Arandjelovic, Relja and Zisserman, Andrew},
	doi = {10.1109/CVPR.2013.207},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/arandjelovic13.pdf:pdf},
	isbn = {978-0-7695-4989-7},
	issn = {10636919},
	journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},
	mendeley-groups = {ML},
	pages = {1578--1585},
	title = {{All About VLAD}},
	url = {http://ieeexplore.ieee.org/document/6619051/},
	year = {2013}
}


@article{Delhumeau2013,
	abstract = {Recent works on image retrieval have proposed to index images by compact representations encoding powerful local descriptors, such as the closely related VLAD and Fisher vector. By combining such a representation with a suitable coding technique, it is possible to encode an image in a few dozen bytes while achieving excellent retrieval results. This paper revisits some assumptions proposed in this context regarding the handling of "visual burstiness", and shows that ad-hoc choices are implicitly done which are not desirable. Focusing on VLAD without loss of generality, we propose to modify several steps of the original design. Albeit simple, these modifications significantly improve VLAD and make it compare favorably against the state of the art.},
	author = {Delhumeau, Jonathan and Gosselin, Philippe-Henri and J{\'{e}}gou, Herv{\'{e}} and P{\'{e}}rez, Patrick},
	doi = {10.1145/2502081.2502171},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/delhumeau13acmm.pdf:pdf},
	isbn = {9781450324045},
	journal = {Proceedings of the 21st ACM international conference on Multimedia - MM '13},
	keywords = {image search,multimedia retrieval,vlad},
	mendeley-groups = {ML},
	pages = {653--656},
	title = {{Revisiting the VLAD image representation}},
	url = {http://dl.acm.org/citation.cfm?doid=2502081.2502171},
	year = {2013}
}




@article{Sanchez2013,
	author = {Sanchez, Jorge and Perronnin, Florent and Mensink, Thomas and Verbeek, Jakob and Classification, Image and Jorge, S and Thomas, Perronnin and Jakob, Mensink},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/RR-8209.pdf:pdf},
	mendeley-groups = {ML},
	title = {{Image Classification with the Fisher Vector : Theory and Practice To cite this version : Image Classification with the Fisher Vector : Theory and Practice}},
	year = {2013}
}


@article{Horning2010,
	abstract = {9-11 December 2010},
	archivePrefix = {arXiv},
	arxivId = {1609-3631},
	author = {Horning, N.},
	doi = {10.5244/C.22.54},
	eprint = {1609-3631},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/04aa1f4a8beb619e7fe711c29b7b.pdf:pdf},
	isbn = {3021077226},
	issn = {1550-5499},
	journal = {International Conference on Geoinformatics for Spatial Infrastructure Development in Earth and Allied Sciences 2010},
	mendeley-groups = {ML},
	pages = {1--6},
	pmid = {21196786},
	title = {{Random Forests: An algorithm for image classification and generation of continuous fields data sets}},
	year = {2010}
}


@article{Bosch2007,
	abstract = {We explore the problem of classifying images by the object categories they contain in the case of a large number of object categories. To this end we combine three ingredients: (i) shape and appearance representations that support spatial pyramid matching over a region of interest. This generalizes the representation of Lazebnik et al [16] from an image to a region of interest (ROI), and from appearance (visual words) alone to appearance and local shape (edge distributions). (ii) automatic selection of the regions of interest in training. This provides a method of inhibiting background clutter and adding invariance to the object instance's position, and (iii) the use of random forests (and random ferns) as a multi-way classifier. The advantage of such classifiers (over multi-way SVM for example) is the ease of training and testing. Results are reported for classification of the Caltech-101 and Caltech-256 data sets. We compare the performance of the random forest/ferns classifier with a benchmark multi-way SVM classifier. It is shown that selecting the ROI adds about 5{\%} to the performance and, together with the other improvements, the result is about a 10{\%} improvement over the state of the art for Caltech-256.},
	author = {Bosch, Anna and Zisserman, Andrew and Mu, Xavier and Munoz, Xavier},
	doi = {10.1109/ICCV.2007.4409066},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/bosch07a.pdf:pdf},
	isbn = {1550-5499 VO -},
	issn = {1550-5499},
	journal = {Computer Vision (ICCV), IEEE 11th International Conference on},
	mendeley-groups = {ML},
	pages = {1--8},
	title = {{Image Classification Using Random Forests and Ferns}},
	url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4409066},
	year = {2007}
}

@article{Singh2012,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1412.7062v1},
	author = {Singh, Nishant and Dubey, Shiv Ram and Dixit, Pushkar and Gupta, Jay Prakash},
	doi = {10.5121/csit.2012.2327},
	eprint = {arXiv:1412.7062v1},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/csit53203 (1).pdf:pdf},
	mendeley-groups = {ML},
	number = {2},
	pages = {277--284},
	title = {{Semantic I Mage R Etrieval U Sing Multiple Features}},
	volume = {5},
	year = {2012}
}


@article{Ke2003,
	author = {Ke, Yan and Sukthankar, Rahul},
	file = {:C$\backslash$:/Users/C40-05/Desktop/MAESTRIA/MATERIAS/2017/SEMESTRE2/ProyectosFinales/Proyecto{\_}MachineLearning/TechnicalReport/references/cvpr2004-keypoint-rahuls.pdf:pdf},
	mendeley-groups = {ML},
	pages = {2--9},
	title = {{A More Distinctive Representation for Local Image Descriptors}},
	year = {2003}
}




