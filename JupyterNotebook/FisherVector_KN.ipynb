{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagedataset as imgdat\n",
    "import fishervector as fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Annotations\n",
    "annotations = imgdat.GetAnnotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all sift descriptors in dataset from file...\n",
      "All descriptors loaded ! \n"
     ]
    }
   ],
   "source": [
    "#Try to load all descriptors previously generated if not generate one\n",
    "try:\n",
    "    all_descriptors = imgdat.LoadAllDescriptors()\n",
    "except:\n",
    "    all_descriptors = imgdat.GenerateAllDescriptors(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use standardscaler for all SIFT descriptors before process them with any representation algorithm.\n",
    "sc_dscs = StandardScaler()\n",
    "all_descriptors = sc_dscs.fit_transform(all_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GMM of size 10\n",
      "Initialization 0\n",
      "  Iteration 0\t time lapse 20.68181s\t ll change inf\n",
      "  Iteration 10\t time lapse 13.07780s\t ll change 0.78599\n",
      "  Iteration 20\t time lapse 12.31716s\t ll change 0.26030\n",
      "  Iteration 30\t time lapse 10.94147s\t ll change 0.23296\n",
      "  Iteration 40\t time lapse 11.43253s\t ll change 0.09523\n",
      "  Iteration 50\t time lapse 11.12592s\t ll change 0.05454\n",
      "  Iteration 60\t time lapse 12.03503s\t ll change 0.02875\n",
      "  Iteration 70\t time lapse 11.20593s\t ll change 0.00625\n",
      "  Iteration 80\t time lapse 11.08394s\t ll change 0.04739\n",
      "  Iteration 90\t time lapse 10.32381s\t ll change 0.00675\n",
      "Initialization converged: False\t time lapse 133.48744s\t ll -107.46818\n",
      "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
      "        means_init=None, n_components=10, n_init=1, precisions_init=None,\n",
      "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=2,\n",
      "        verbose_interval=10, warm_start=False, weights_init=None)\n",
      "Saving gmm at: means.gmm.npy, covs.gmm.npy, weights.gmm.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\tensorflowproject\\lib\\site-packages\\sklearn\\mixture\\base.py:237: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Clustering descriptors using KMeans in 120 classes \n",
    "try:\n",
    "    gmm_fv = fv.LoadKmeans()\n",
    "except:\n",
    "    n_clusters = 10\n",
    "    gmm_fv = fv.GenerateGmm(all_descriptors, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image representation\n",
    "try:\n",
    "    X_fv = np.load(\"fv_X.npy\")\n",
    "    y_fv = np.load(\"fv_y.npy\")\n",
    "except:\n",
    "    X_fv, y_fv = fv.FisherFeatures(annotations, gmm_fv, sc_dscs)\n",
    "    np.save(\"fv_X\", X_fv)\n",
    "    np.save(\"fv_y\", y_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification \n",
    "#Dataset splitting into the training set and test set\n",
    "X_train_fv, X_test_fv, y_train_fv, y_test_fv = train_test_split(X_fv, y_fv, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling representation features\n",
    "sc_repr_fv = StandardScaler()\n",
    "X_train_fv = sc_repr_fv.fit_transform(X_train_fv)\n",
    "X_test_fv = sc_repr_fv.transform(X_test_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "train score:0.931297709924\n",
      "test score:0.787878787879\n",
      "[[19 19]\n",
      " [ 2 59]]\n"
     ]
    }
   ],
   "source": [
    "#Using k-nearest neighbors Classifier\n",
    "clf_kn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_kn.fit(X_train_fv, y_train_fv)\n",
    "print('==========')\n",
    "print('train score:' + str(clf_kn.score(X_train_fv,y_train_fv)))\n",
    "print('test score:' + str(clf_kn.score(X_test_fv,y_test_fv)))\n",
    "y_pred = clf_kn.predict(X_test_fv)\n",
    "y_pred = (y_pred > 0.5)\n",
    "cm = confusion_matrix(y_test_fv, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
