{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path Config\n",
    "path = \"dataset-1.0/\"\n",
    "subpath_annotations = \"annotations/\"\n",
    "subpath_images = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Annotations Filenames\n",
    "annotation_path = lambda i: path+subpath_annotations+\"%03d\"%(i)+\"_annotation.yaml\"\n",
    "annotations = [annotation_path(i+1) for i in range(60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_json = []\n",
    "for annotation in annotations:\n",
    "    with open(annotation, 'r') as stream:\n",
    "        try:\n",
    "            annotations_json.append(yaml.load(stream))\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      "  126 127]]\n"
     ]
    }
   ],
   "source": [
    "#Total Descriptors for BoW\n",
    "total_descriptors = np.arange(128).reshape(1,128)\n",
    "print(total_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = ([15, 90, 20], [110, 230, 80])\n",
    "lower = np.array(boundary[0],dtype=np.uint8)\n",
    "upper = np.array(boundary[1],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001_image.png\n",
      "002_image.png\n",
      "003_image.png\n",
      "004_image.png\n",
      "005_image.png\n",
      "006_image.png\n",
      "007_image.png\n",
      "008_image.png\n",
      "009_image.png\n",
      "No se pudo generar la region\n",
      "010_image.png\n",
      "011_image.png\n",
      "012_image.png\n",
      "013_image.png\n",
      "014_image.png\n",
      "015_image.png\n",
      "016_image.png\n",
      "017_image.png\n",
      "018_image.png\n",
      "No se pudo generar la region\n",
      "019_image.png\n",
      "020_image.png\n",
      "021_image.png\n",
      "022_image.png\n",
      "023_image.png\n",
      "024_image.png\n",
      "025_image.png\n",
      "026_image.png\n",
      "027_image.png\n",
      "028_image.png\n",
      "029_image.png\n",
      "030_image.png\n",
      "031_image.png\n",
      "032_image.png\n",
      "033_image.png\n",
      "034_image.png\n",
      "035_image.png\n",
      "036_image.png\n",
      "037_image.png\n",
      "038_image.png\n",
      "039_image.png\n",
      "040_image.png\n",
      "041_image.png\n",
      "042_image.png\n",
      "043_image.png\n",
      "044_image.png\n",
      "045_image.png\n",
      "046_image.png\n",
      "047_image.png\n",
      "048_image.png\n",
      "049_image.png\n",
      "050_image.png\n",
      "051_image.png\n",
      "052_image.png\n",
      "053_image.png\n",
      "054_image.png\n",
      "055_image.png\n",
      "056_image.png\n",
      "057_image.png\n",
      "058_image.png\n",
      "059_image.png\n",
      "060_image.png\n",
      "(74554, 128)\n"
     ]
    }
   ],
   "source": [
    "for annotation in annotations_json:\n",
    "    image_file = annotation['filename']\n",
    "    print(image_file)\n",
    "    img = cv2.imread(path+subpath_images+image_file)\n",
    "    regions = annotation['annotation']\n",
    "    \n",
    "    for region in regions:\n",
    "        points = region['points']       \n",
    "        px = points['x']\n",
    "        py = points['y']\n",
    "        \n",
    "        if(type(px) is list):\n",
    "            pts = np.array([[int(x),int(y)] for x,y in zip(px,py)], dtype=np.int32)\n",
    "            mask_region = np.zeros(img.shape, dtype=np.uint8)\n",
    "            cv2.fillConvexPoly(mask_region, pts, (255,255,255))\n",
    "            masked_region = cv2.bitwise_and(img,mask_region)\n",
    "            mask_color = cv2.inRange(masked_region, lower, upper)\n",
    "            masked_color = cv2.bitwise_and(masked_region, masked_region, mask = mask_color)\n",
    "            kps , descriptors = cv2.xfeatures2d.SIFT_create().detectAndCompute(masked_color, None)\n",
    "            total_descriptors = np.append(total_descriptors, descriptors, axis=0)\n",
    "\n",
    "        else:\n",
    "            print('No se pudo generar la region')\n",
    "        \n",
    "total_descriptors = np.delete(total_descriptors, 0, 0)\n",
    "print(total_descriptors.shape)\n",
    "np.save('total_descriptors_plants', total_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.   1.   0. ...,   0.   0.   0.]\n",
      " [ 71.  23.  75. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,   5.  11.  58.]\n",
      " ..., \n",
      " [  2.   1.   0. ...,  64.   1.   8.]\n",
      " [  0.   0.   0. ...,  41.   0.   0.]\n",
      " [  1.   0.   0. ...,   0.   0.   0.]]\n",
      "(74554, 128)\n"
     ]
    }
   ],
   "source": [
    "# Cluster BoW\n",
    "total_descriptors = np.load('total_descriptors_plants.npy')\n",
    "print(total_descriptors)\n",
    "print(total_descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sc_descriptors.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "sc_descriptors = StandardScaler()\n",
    "total_descriptors = sc_descriptors.fit_transform(total_descriptors)\n",
    "# save standard scaler\n",
    "joblib.dump(sc_descriptors, 'sc_descriptors.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "n_words=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_words, max_iter=2000).fit(total_descriptors)\n",
    "print(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
