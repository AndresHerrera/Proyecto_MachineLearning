{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagedataset as imgdat\n",
    "import vlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Annotations\n",
    "annotations = imgdat.GetAnnotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all sift descriptors in dataset from file...\n",
      "All descriptors loaded ! \n"
     ]
    }
   ],
   "source": [
    "#Try to load all descriptors previously generated if not generate one\n",
    "try:\n",
    "    all_descriptors = imgdat.LoadAllDescriptors()\n",
    "except:\n",
    "    all_descriptors = imgdat.GenerateAllDescriptors(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use standardscaler for all SIFT descriptors before process them with any representation algorithm.\n",
    "sc_dscs = StandardScaler()\n",
    "all_descriptors = sc_dscs.fit_transform(all_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading kmeans...\n",
      "Training GMM of size 120\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=2000,\n",
      "    n_clusters=120, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n",
      "Saving kmeans at: vlad_centers.kmeans.npy\n"
     ]
    }
   ],
   "source": [
    "#Clustering descriptors using KMeans in 120 classes \n",
    "try:\n",
    "    kmeans_vlad = vlad.LoadKmeans()\n",
    "except:\n",
    "    n_clusters = 120\n",
    "    kmeans_vlad = vlad.GenerateKmeans(all_descriptors, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo generar la region in : 009_image.png\n",
      "No se pudo generar la region in : 018_image.png\n"
     ]
    }
   ],
   "source": [
    "#Image representation\n",
    "try:\n",
    "    X_vlad = np.load(\"vlad_X.npy\")\n",
    "    y_vlad = np.load(\"vlad_y.npy\")\n",
    "except:\n",
    "    X_vlad, y_vlad = vlad.VladFeatures(annotations, kmeans_vlad, sc_dscs)\n",
    "    np.save(\"vlad_X\", X_vlad)\n",
    "    np.save(\"vlad_y\", y_vlad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification \n",
    "#Dataset splitting into the training set and test set\n",
    "X_train_vlad, X_test_vlad, y_train_vlad, y_test_vlad = train_test_split(X_vlad, y_vlad, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling representation features\n",
    "sc_repr_vlad = StandardScaler()\n",
    "X_train_vlad = sc_repr_vlad.fit_transform(X_train_vlad)\n",
    "X_test_vlad = sc_repr_vlad.transform(X_test_vlad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a MLP\n",
    "n_layers = 2\n",
    "\n",
    "for x in range (100,120):\n",
    "    n_neurons = x\n",
    "#n_neurons = 100\n",
    "    clf_mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=np.ones(n_layers).astype(int)*n_neurons, \n",
    "        max_iter=1000,\n",
    "        shuffle = True,\n",
    "        alpha = 0.01)\n",
    "    clf_mlp.fit(X_train_vlad, y_train_vlad)\n",
    "    \n",
    "    print('==========')\n",
    "    print('score: '+str(clf_mlp.score(X_test_vlad,y_test_vlad)))\n",
    "\n",
    "    y_pred = clf_mlp.predict(X_test_vlad)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    cm = confusion_matrix(y_test_vlad, y_pred)\n",
    "\n",
    "    print('n_neurons: '+str(n_neurons))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
