{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path Config\n",
    "path = \"dataset-1.0/\"\n",
    "subpath_annotations = \"annotations/\"\n",
    "subpath_images = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAnnotations():    \n",
    "    annotation_path = lambda i: path+subpath_annotations+\"%03d\"%(i)+\"_annotation.yaml\"\n",
    "    annotations = [annotation_path(i+1) for i in range(60)]\n",
    "    annotations_json = []\n",
    "    for annotation in annotations:\n",
    "        with open(annotation, 'r') as stream:\n",
    "            try:\n",
    "                annotations_json.append(yaml.load(stream))\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "    return annotations_json# Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features\n",
    "boundary = ([15, 90, 20], [110, 230, 80])\n",
    "lower = np.array(boundary[0],dtype=np.uint8)\n",
    "upper = np.array(boundary[1],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadAllDescriptors():\n",
    "    print(\"Loading all sift descriptors in dataset from file...\")\n",
    "    all_descriptors = np.load('all_descriptorsrgb.npy')\n",
    "    print(\"All descriptors loaded ! \")\n",
    "    return all_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateAllDescriptors(annotations):\n",
    "    print(\"Extracting all sift descriptors in dataset......\")\n",
    "    all_descriptors = np.arange(128).reshape(1,128)\n",
    "    for annotation in annotations:\n",
    "        image_file = annotation['filename']\n",
    "        img = cv2.imread(path+subpath_images+image_file)\n",
    "        regions = annotation['annotation']\n",
    "        for region in regions:\n",
    "            points = region['points']\n",
    "            px = points['x']\n",
    "            py = points['y']\n",
    "            if(type(px) is list):\n",
    "                pts = np.array([[int(x),int(y)] for x,y in zip(px,py)], dtype=np.int32)\n",
    "                mask_region = np.zeros(img.shape, dtype=np.uint8)\n",
    "                cv2.fillConvexPoly(mask_region, pts, (255,255,255))\n",
    "                masked_region = cv2.bitwise_and(img,mask_region)\n",
    "                mask_color = cv2.inRange(masked_region, lower, upper)\n",
    "                masked_color = cv2.bitwise_and(masked_region, masked_region, mask = mask_color)\n",
    "                kps , descriptors = cv2.xfeatures2d.SIFT_create().detectAndCompute(masked_color, None)\n",
    "                all_descriptors = np.append(all_descriptors, descriptors, axis=0)\n",
    "            else:\n",
    "                print('No se pudo generar la region')\n",
    "    all_descriptors = np.delete(all_descriptors, 0, 0)\n",
    "    print(\"All descriptors extracted successfully with shape {}\".format(all_descriptors.shape))\n",
    "    print(\"Saving all descriptors at all_descriptorsrgb.npy\")\n",
    "    np.save('all_descriptorsrgb', all_descriptors)\n",
    "    return all_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFeatures(feature_vector, *args):\n",
    "    annotations = args[0]\n",
    "    vector_len = args[1]\n",
    "    cluster = args[2]\n",
    "    scaler = args[3]\n",
    "    y = np.array([])\n",
    "    X = np.arange(vector_len).reshape(1,vector_len)\n",
    "    for annotation in annotations:\n",
    "        image_file = annotation['filename']\n",
    "        img = cv2.imread(path+subpath_images+image_file)\n",
    "        regions = annotation['annotation']\n",
    "        for region in regions:\n",
    "            points = region['points']\n",
    "            px = points['x']\n",
    "            py = points['y']\n",
    "            if(type(px) is list):\n",
    "                pts = np.array([[int(x),int(y)] for x,y in zip(px,py)], dtype=np.int32)\n",
    "                mask_region = np.zeros(img.shape, dtype=np.uint8)\n",
    "                cv2.fillConvexPoly(mask_region, pts, (255,255,255))\n",
    "                masked_region = cv2.bitwise_and(img,mask_region)\n",
    "                mask_color = cv2.inRange(masked_region, lower, upper)\n",
    "                masked_color = cv2.bitwise_and(masked_region, masked_region, mask = mask_color)\n",
    "                kps , descriptors = cv2.xfeatures2d.SIFT_create().detectAndCompute(masked_color, None)\n",
    "                descriptors = scaler.transform(descriptors)\n",
    "                X = np.append(X, feature_vector(descriptors, *cluster).reshape(1,vector_len), axis=0)\n",
    "                y = np.append(y, region['type'])\n",
    "            else:\n",
    "                print('No se pudo generar la region in : ' + image_file)\n",
    "    \n",
    "    X = np.delete(X, 0, 0)\n",
    "    # encoding categorical data\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Annotations\n",
    "annotations = GetAnnotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all sift descriptors in dataset from file...\n",
      "Extracting all sift descriptors in dataset......\n"
     ]
    }
   ],
   "source": [
    "#Try to load all descriptors previously generated if not generate one\n",
    "try:\n",
    "    all_descriptors = LoadAllDescriptors()\n",
    "except:\n",
    "    all_descriptors = GenerateAllDescriptors(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use standardscaler for all SIFT descriptors before process them with any representation algorithm.\n",
    "sc_dscs = StandardScaler()\n",
    "all_descriptors = sc_dscs.fit_transform(all_descriptors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
